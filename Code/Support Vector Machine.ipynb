{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Making an predictive model using Support Vector Machine</h1>\n",
    "In deze jupyter notebook file, worden de de decision tree gemaakt. \n",
    "Dit wordt gedaan om de onderzoeksvraag van mijn thesis te kunnen beantwoorden:\n",
    "To what extent can support vector machine, randomforest tree, or Gradient Boosting Machine contributeto predicting the demand for the specialist youth caresegments in Amsterdam?\n",
    "Ook is dit nodig voor het beantwoorden van mijn sub vraen:\n",
    "•Are there neighborhood socio-demographic characteristics which are predictive of the use of youth caresegments?\n",
    "•Which of the tested models has the highest f1 score in predicting the youth care segment use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hier onder worden eerst de benodigde librabry geimporteerd</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import mean\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de sub onderzoeks vraag: Which of the tested models has the highest f1-score in predicting the youth care segment use? Waarom we voor deze score hebben gekozen, kan gelezen worden onder het kopje \"model eveluation\".\n",
    "\n",
    "Ook maken we een aantal variabele hier aan om de code zo gestructuurd mogelijk te houden. Waarom deze nodig zijn, valt te lezen in het kopje \"model making'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " def calculateMetrics(model):\n",
    "        y_predicted = model.predict(X_test_scaled)\n",
    "        print(model)\n",
    "        print (\"F1 score\")\n",
    "        print(f1_score(y_test, y_predicted, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Laad de data in, die gemaakt is uit de andere jupyter notebook file</h3>\n",
    "Split the data in indepentend variable an dependent variable. Also get dummies from the binary values in the data set. Why we do this, can be found in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "df = pd.read_pickle(\"C:\\\\VERTROUWELIJK\\\\final_dataSet.pkl\")\n",
    "\n",
    "# split the data in indepentend variable an dependent variable. \n",
    "X = df.drop(['Voorziening'], axis=1)\n",
    "X_encoded = pd.get_dummies(X, columns=['Geslacht'])\n",
    "X_Original_Scaled = scale(X_encoded)\n",
    "\n",
    "y = df['Voorziening'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform the dependent variable to value instead of strings. This is needed for making an good SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make test and train set. Also scale the data. Which is neccesary for SVM.  Waarom dit nodig is, zie \"making model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded,y,random_state=100)\n",
    "X_train_scaled = scale(X_train)\n",
    "X_test_scaled = scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create inital SVM model, with an decision function for one vs one. An CV is used in order to shuffle the train data. See report.  Immedelty calcutale the F1 score to compare this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(decision_function_shape='ovo', random_state=42)\n",
      "f1_score: 24.88%\n"
     ]
    }
   ],
   "source": [
    "clf_svm = SVC(decision_function_shape='ovo', random_state=42)\n",
    "print(clf_svm)\n",
    "scores = cross_val_score(clf_svm, X_train_scaled, y_train, cv=5, scoring='f1_micro')\n",
    "score = mean(scores)\n",
    "print(\"f1_score: %.2f%%\" % (score * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based nt he above F1 score, I choose to make more model SVC models, with different kernels in order the get the best kernel for this SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(decision_function_shape='ovo', kernel='linear')\n",
      "F1 score\n",
      "0.34709294482665587\n",
      "SVC(decision_function_shape='ovo')\n",
      "F1 score\n",
      "0.24780790503170105\n",
      "SVC(decision_function_shape='ovo', kernel='poly')\n",
      "F1 score\n",
      "0.23054094158910027\n",
      "SVC(decision_function_shape='ovo', kernel='sigmoid')\n",
      "F1 score\n",
      "0.16201268042627817\n"
     ]
    }
   ],
   "source": [
    "linear = SVC(kernel='linear', decision_function_shape='ovo').fit(X_train_scaled, y_train)\n",
    "calculateMetrics(linear)\n",
    "rbf = SVC(kernel='rbf', decision_function_shape='ovo').fit(X_train_scaled, y_train)\n",
    "calculateMetrics(rbf)\n",
    "poly = SVC(kernel='poly', decision_function_shape='ovo').fit(X_train_scaled, y_train)\n",
    "calculateMetrics(poly)\n",
    "sig = SVC(kernel='sigmoid', decision_function_shape='ovo').fit(X_train_scaled, y_train)\n",
    "calculateMetrics(sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals gezegd, de data is erg imbalanced. Daarom maken we een decision tree with random undersampling. Zie model making in report voor meer uitleg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.068\n"
     ]
    }
   ],
   "source": [
    "steps = [('under', RandomUnderSampler()), ('model', SVC(decision_function_shape='ovo', random_state=42))]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=100, n_repeats=5, random_state=42)\n",
    "scores = cross_val_score(pipeline, X_Original_Scaled, y, scoring='f1_micro', cv=cv, n_jobs=-1)\n",
    "# calculate the mean of all these SVC. \n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Result part, we described that we not made the GridSearchCV for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [ {'C': [1.0]},\n",
    "#      'kernel': ['linear'],\n",
    "#     {'gamma': [1.0]}\n",
    "#              ]\n",
    "\n",
    "# cv_method = RepeatedStratifiedKFold(n_splits=5, \n",
    "#                                     n_repeats=3, \n",
    "#                                     random_state=42)\n",
    "# optimal_params = GridSearchCV(\n",
    "# SVC(decision_function_shape='ovo', random_state=42),\n",
    "# param_grid, \n",
    "# scoring='f1_micro',\n",
    "# verbose =10\n",
    "# )\n",
    "\n",
    "# optimal_params.fit(X_Original_Scaled,y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
