{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Making an predictive model using Gradient Boosting Machine</h1>\n",
    "In deze jupyter notebook file, worden de de decision tree gemaakt. \n",
    "Dit wordt gedaan om de onderzoeksvraag van mijn thesis te kunnen beantwoorden:\n",
    "To what extent can support vector machine, randomforest tree, or Gradient Boosting Machine contributeto predicting the demand for the specialist youth caresegments in Amsterdam?\n",
    "Ook is dit nodig voor het beantwoorden van mijn sub vraen:\n",
    "•Are there neighborhood socio-demographic characteristics which are predictive of the use of youth caresegments?\n",
    "•Which of the tested models has the highest f1 score in predicting the youth care segment use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hier onder worden eerst de benodigde librabry geimporteerd</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost import plot_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de sub onderzoeks vraag: Which of the tested models has the highest f1-score in predicting the youth care segment use? Waarom we voor deze score hebben gekozen, kan gelezen worden onder het kopje \"model eveluation\".\n",
    "\n",
    "Ook maken we een aantal variabele hier aan om de code zo gestructuurd mogelijk te houden. Waarom deze nodig zijn, valt te lezen in het kopje \"model making'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some variables\n",
    "param_grid = {\n",
    "        'max_depth': range(4,26,4),\n",
    "        'scale_pos_weight' : [1, 25, 50, 75, 100],\n",
    "        'colsample_bytree': np.arange(0.5,1.0,0.3),\n",
    "}\n",
    "\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=2, \n",
    "                                    n_repeats=1, \n",
    "                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Laad de data in, die gemaakt is uit de andere jupyter notebook file</h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "df = pd.read_pickle(\"C:\\\\VERTROUWELIJK\\\\final_dataSet.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in indepentend variable an dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Voorziening'], axis=1)\n",
    "X_encoded = pd.get_dummies(X, columns=['Geslacht'])\n",
    "y = df['Voorziening'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode string class values as integers, which is needed for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(y)\n",
    "label_encoded_y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make train and test set. Waarom dit nodig is, zie \"making model\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_encoded, label_encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make the first gradient Boosting</h3>\n",
    "and fit this to get the scores. Dit is nodig om alle onderzoeksvragen mee te bentwoorden.\n",
    "Zie \"model\" in de thesis waarom we voro xgboost hebben gekozen en niet noor de standaard aangeleverde vanuit sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "start_time=time.time()\n",
    "# model.fit(X_train, y_train)\n",
    "print(model)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "score = mean(scores)\n",
    "print(\"f1_score: %.2f%%\" % (score * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals gezegd, de data is erg imbalanced. Daarom maken we een decision tree with random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [('under', RandomUnderSampler()), ('model', xgboost.XGBClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=42)\n",
    "scores = cross_val_score(pipeline, X_encoded, label_encoded_y, scoring='f1_micro', cv=cv, n_jobs=-1, verbose = 10)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prune the model</h3>\n",
    "Na het vergelijken van de twee modellen, heeft het model met de normale data set de hoogste F1 score, hier na gaan we het model nog prunen. Zie Making Model in de thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an gridSearch\n",
    "start_time=time.time()\n",
    "grid = GridSearchCV(xgboost.XGBClassifier(),\n",
    "                   param_grid=param_grid,\n",
    "                    scoring='f1_micro',\n",
    "                   verbose=10,\n",
    "                    cv= cv_method,\n",
    "                   n_jobs=-1)\n",
    "start_time=time.time()\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best F1 score, coming from the gridSearch.\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best parameters of coming from the gridSearch.\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de onderzoeks vraag: Are there neighborhood socio-demographic characteristics which are predictive of the use of youth caresegments? is onderstaande code nodig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 10 most important features of the XGboost model\n",
    "plot_importance(model, max_num_features=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
