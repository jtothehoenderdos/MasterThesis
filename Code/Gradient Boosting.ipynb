{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Making an predictive model using Gradient Boosting Machine</h1>\n",
    "In deze jupyter notebook file, worden de de decision tree gemaakt. \n",
    "Dit wordt gedaan om de onderzoeksvraag van mijn thesis te kunnen beantwoorden:\n",
    "To what extent can support vector machine, randomforest tree, or Gradient Boosting Machine contributeto predicting the demand for the specialist youth caresegments in Amsterdam?\n",
    "Ook is dit nodig voor het beantwoorden van mijn sub vraen:\n",
    "•Are there neighborhood socio-demographic characteristics which are predictive of the use of youth caresegments?\n",
    "•Which of the tested models has the highest f1 score in predicting the youth care segment use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Hier onder worden eerst de benodigde librabry geimporteerd</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from xgboost import plot_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de sub onderzoeks vraag: Which of the tested models has the highest f1-score in predicting the youth care segment use? Waarom we voor deze score hebben gekozen, kan gelezen worden onder het kopje \"model eveluation\".\n",
    "\n",
    "Ook maken we een aantal variabele hier aan om de code zo gestructuurd mogelijk te houden. Waarom deze nodig zijn, valt te lezen in het kopje \"model making'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some variables\n",
    "param_grid = {\n",
    "        'max_depth': range(4,26,4),\n",
    "        'scale_pos_weight' : [1, 25, 50, 75, 100],\n",
    "        'colsample_bytree': np.arange(0.5,1.0,0.3),\n",
    "}\n",
    "\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=2, \n",
    "                                    n_repeats=1, \n",
    "                                    random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Laad de data in, die gemaakt is uit de andere jupyter notebook file</h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"C:\\\\VERTROUWELIJK\\\\final_dataSet.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in indepentend variable an dependent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Voorziening'], axis=1)\n",
    "X_encoded = pd.get_dummies(X, columns=['Geslacht'])\n",
    "y = df['Voorziening'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode string class values as integers, which is needed for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(y)\n",
    "label_encoded_y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make train and test set. Waarom dit nodig is, zie \"making model\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X_encoded, label_encoded_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make the first gradient Boosting</h3>\n",
    "and fit this to get the scores. Dit is nodig om alle onderzoeksvragen mee te bentwoorden.\n",
    "Zie \"model\" in de thesis waarom we voro xgboost hebben gekozen en niet noor de standaard aangeleverde vanuit sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "f1_score: 60.38%\n",
      "f1_score STD\n",
      "0.005676588725797207\n"
     ]
    }
   ],
   "source": [
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "start_time=time.time()\n",
    "# model.fit(X_train, y_train)\n",
    "print(model)\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1_micro')\n",
    "score = mean(scores)\n",
    "print(\"f1_score: %.2f%%\" % (score * 100.0))\n",
    "std_scores = scores.std()\n",
    "print(\"f1_score STD\")\n",
    "print(std_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoals gezegd, de data is erg imbalanced. Daarom maken we een decision tree with random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.249\n",
      "f1_score STD\n",
      "0.0057331714555510505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   48.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   48.0s finished\n"
     ]
    }
   ],
   "source": [
    "steps = [('under', RandomUnderSampler()), ('model', xgboost.XGBClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# evaluate pipeline\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=42)\n",
    "scores = cross_val_score(pipeline, X_encoded, label_encoded_y, scoring='f1_micro', cv=cv, n_jobs=-1, verbose = 10)\n",
    "score = mean(scores)\n",
    "print('F1 Score: %.3f' % score)\n",
    "std_scores = scores.std()\n",
    "print(\"f1_score STD\")\n",
    "print(std_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prune the model</h3>\n",
    "Na het vergelijken van de twee modellen, heeft het model met de normale data set de hoogste F1 score, hier na gaan we het model nog prunen. Zie Making Model in de thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 60 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 39.3min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 50.5min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 63.4min\n",
      "[Parallel(n_jobs=-1)]: Done 118 out of 120 | elapsed: 78.3min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 79.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:57:59] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { scale_pos_weight } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "4816.003154754639\n"
     ]
    }
   ],
   "source": [
    "# make an gridSearch\n",
    "start_time=time.time()\n",
    "grid = GridSearchCV(xgboost.XGBClassifier(),\n",
    "                   param_grid=param_grid,\n",
    "                    scoring='f1_micro',\n",
    "                   verbose=10,\n",
    "                    cv= cv_method,\n",
    "                   n_jobs=-1)\n",
    "start_time=time.time()\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the scores of the GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002120629454342604"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_['std_test_score'][grid.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8, 'max_depth': 4, 'scale_pos_weight': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best parameters of coming from the gridSearch.\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5792789028356375"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the best F1 score, coming from the gridSearch.\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de onderzoeks vraag: Are there neighborhood socio-demographic characteristics which are predictive of the use of youth caresegments? is onderstaande code nodig. Echter voeren wij deze niet uit, omdat Decicion tree een hogere F1 score heeft. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 10 most important features of the XGboost model\n",
    "# xgboost.plot_importance(model, max_num_features=10)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
